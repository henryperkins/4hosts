
# ============================================================================
# FOUR HOSTS RESEARCH APPLICATION - DOCKER COMPOSE CONFIGURATION
# ============================================================================
# This stack runs the complete Four Hosts research system with:
# - PostgreSQL database for persistent data storage
# - Redis cache for session management and performance optimization
# - FastAPI backend with paradigm-aware research capabilities
# - React frontend for user interaction
# ============================================================================

# Reusable env anchors
x-backend-exa-env: &backend-exa-env
  EXA_API_KEY: ${EXA_API_KEY:-}
  SEARCH_DISABLE_EXA: ${SEARCH_DISABLE_EXA:-0}
  EXA_INCLUDE_TEXT: ${EXA_INCLUDE_TEXT:-0}
  EXA_SEARCH_AS_PRIMARY: ${EXA_SEARCH_AS_PRIMARY:-0}
  EXA_BASE_URL: ${EXA_BASE_URL:-https://api.exa.ai}
  EXA_TIMEOUT_SEC: ${EXA_TIMEOUT_SEC:-15}

# Optional: Unified Query Planner knobs (safe to leave unset)
x-backend-planner-env: &backend-planner-env
  UNIFIED_QUERY_MAX_VARIATIONS: ${UNIFIED_QUERY_MAX_VARIATIONS:-}
  UNIFIED_QUERY_STAGE_ORDER: ${UNIFIED_QUERY_STAGE_ORDER:-}
  UNIFIED_QUERY_STAGE_PRIORS: ${UNIFIED_QUERY_STAGE_PRIORS:-}
  UNIFIED_QUERY_ENABLE_LLM: ${UNIFIED_QUERY_ENABLE_LLM:-}
  UNIFIED_QUERY_ENABLE_FOLLOW_UP: ${UNIFIED_QUERY_ENABLE_FOLLOW_UP:-}
  UNIFIED_QUERY_DEDUP_JACCARD: ${UNIFIED_QUERY_DEDUP_JACCARD:-0.92}

services:
  # ==========================================================================
  # DATABASE SERVICE - PostgreSQL
  # ==========================================================================
  # Primary data store for user accounts, research history, and system data
  postgres:
    # Using 15-alpine to match existing data directory initialized under PG 15.
    # Upgrade path: run 15 -> dump or pg_upgrade to 16, then retag.
    image: postgres:15-alpine
    # container_name removed to avoid conflicts when running multiple stacks.
    # Docker Compose will auto-name the container (project_service_index) and
    # service DNS remains 'postgres' for inter-service communication.
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      POSTGRES_DB: fourhosts
    ports:
      - "127.0.0.1:5433:5432"  # Bind to loopback to avoid internet exposure
    volumes:
      # Persistent volume for database data (survives container restarts)
      - postgres_data:/var/lib/postgresql/data
      # Initialize database schema on first run (read-only mount)
      - ./backend/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user -d fourhosts"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s  # Give database time to initialize
    restart: unless-stopped
    networks:
      - fourhosts-network
    labels:
      com.fourhosts.service: "database"
      com.fourhosts.description: "PostgreSQL database for user data and research history"

  # ==========================================================================
  # CACHE SERVICE - Redis
  # ==========================================================================
  # High-performance cache for sessions, rate limiting, and temporary data
  redis:
    image: redis:7-alpine
    # container_name removed to prevent collision with backend-only compose file.
    # Port mapping removed: services communicate over internal network at redis:6379.
    # Exposing Redis to host is unnecessary for normal app operation and caused
    # a port allocation conflict when 6380 was already in use. If external
    # access is required for debugging, re-add a mapping like '6381:6379'.
    volumes:
      # Persistent volume for Redis data (optional persistence)
      - redis_data:/data
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD:-Twiohmld1234!}
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 300
      --protected-mode yes
      --bind 0.0.0.0
    environment:
      REDIS_PASSWORD: ${REDIS_PASSWORD:-Twiohmld1234!}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-Twiohmld1234!}", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    restart: unless-stopped
    networks:
      - fourhosts-network
    labels:
      com.fourhosts.service: "cache"
      com.fourhosts.description: "Redis cache for sessions and performance optimization"
    security_opt:
      - no-new-privileges:true

  # ==========================================================================
  # BACKEND SERVICE - FastAPI Application
  # ==========================================================================
  # Core research engine with paradigm classification and AI-powered answers
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: fourhosts-backend
    environment:
      # Database connection (uses internal Docker network hostname)
      DATABASE_URL: postgresql+asyncpg://user:password@postgres:5432/fourhosts

      # Environment mode - development enables debug features and relaxed CORS
      ENVIRONMENT: development

      # Cache connection with authentication (password URL-encoded)
      REDIS_URL: redis://:${REDIS_PASSWORD_ENCODED:-Twiohmld1234%21}@redis:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD:-Twiohmld1234!}
      # JWT signing key (development default; override via .env in real use)
      JWT_SECRET_KEY: ${JWT_SECRET_KEY:-insecure-dev-token-change-me}

      # Search orchestration tuning (safer defaults)
      SEARCH_TASK_TIMEOUT_SEC: ${SEARCH_TASK_TIMEOUT_SEC:-30}
      SEARCH_PROVIDER_TIMEOUT_SEC: ${SEARCH_PROVIDER_TIMEOUT_SEC:-25}
      SEARCH_QUERY_CONCURRENCY: ${SEARCH_QUERY_CONCURRENCY:-3}
      SEARCH_FETCH_CONCURRENCY: ${SEARCH_FETCH_CONCURRENCY:-6}

      # Optional provider keys (populate via .env)
      GOOGLE_CSE_API_KEY: ${GOOGLE_CSE_API_KEY:-}
      GOOGLE_CSE_CX: ${GOOGLE_CSE_CX:-}
      BRAVE_SEARCH_API_KEY: ${BRAVE_SEARCH_API_KEY:-}

      # Azure OpenAI Configuration
      AZURE_OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT:-}
      AZURE_OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY:-}
      AZURE_OPENAI_DEPLOYMENT: ${AZURE_OPENAI_DEPLOYMENT:-}
      AZURE_OPENAI_API_VERSION: ${AZURE_OPENAI_API_VERSION:-}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      DEEP_RESEARCH_MODEL: ${DEEP_RESEARCH_MODEL:-o3}

      # Exa and Planner env from anchors
      <<: [*backend-exa-env, *backend-planner-env]

      # Feature flags
      ENABLE_QUERY_LLM: ${ENABLE_QUERY_LLM:-1}
      ENABLE_DYNAMIC_ACTIONS: ${ENABLE_DYNAMIC_ACTIONS:-1}
      ENABLE_MESH_NETWORK: ${ENABLE_MESH_NETWORK:-1}
      ENABLE_MCP_DEFAULT: ${ENABLE_MCP_DEFAULT:-1}
      ENABLE_BRAVE_GROUNDING: ${ENABLE_BRAVE_GROUNDING:-1}
      BRAVE_ENABLE_RESEARCH: ${BRAVE_ENABLE_RESEARCH:-1}
      ENABLE_PROMPT_AB: ${ENABLE_PROMPT_AB:-0}
      PROMPT_AB_WEIGHTS: ${PROMPT_AB_WEIGHTS:-'{"v1":0.5,"v2":0.5}'}

      # Agentic loop configuration
      AGENTIC_DISABLE: ${AGENTIC_DISABLE:-0}
      AGENTIC_ENABLE_LLM_CRITIC: ${AGENTIC_ENABLE_LLM_CRITIC:-1}
      AGENTIC_MAX_ITERATIONS: ${AGENTIC_MAX_ITERATIONS:-2}
      AGENTIC_COVERAGE_THRESHOLD: ${AGENTIC_COVERAGE_THRESHOLD:-0.75}
      AGENTIC_MAX_NEW_QUERIES_PER_ITER: ${AGENTIC_MAX_NEW_QUERIES_PER_ITER:-4}

      # LLM configuration
      LLM_REQUIRED: ${LLM_REQUIRED:-0}
      AZURE_OPENAI_USE_RESPONSES: ${AZURE_OPENAI_USE_RESPONSES:-1}

      # Search configuration
      SEARCH_USE_PRIORITY_MODE: ${SEARCH_USE_PRIORITY_MODE:-1}
      SEARCH_MIN_RESULTS_THRESHOLD: ${SEARCH_MIN_RESULTS_THRESHOLD:-5}
      SEARCH_ACADEMIC_TIMEOUT_SEC: ${SEARCH_ACADEMIC_TIMEOUT_SEC:-20}
      SEARCH_QUOTA_COOLDOWN_SEC: ${SEARCH_QUOTA_COOLDOWN_SEC:-3600}
      SEARCH_QUERY_VARIATIONS_LIMIT: ${SEARCH_QUERY_VARIATIONS_LIMIT:-4}
      SEARCH_ALLOW_NLTK_DOWNLOADS: ${SEARCH_ALLOW_NLTK_DOWNLOADS:-1}

      # Search provider toggles
      SEARCH_DISABLE_GOOGLE: ${SEARCH_DISABLE_GOOGLE:-0}
      SEARCH_DISABLE_BRAVE: ${SEARCH_DISABLE_BRAVE:-0}
      SEARCH_DISABLE_ARXIV: ${SEARCH_DISABLE_ARXIV:-0}
      SEARCH_DISABLE_CROSSREF: ${SEARCH_DISABLE_CROSSREF:-0}
      SEARCH_DISABLE_SEMANTICSCHOLAR: ${SEARCH_DISABLE_SEMANTICSCHOLAR:-0}
      SEARCH_DISABLE_PUBMED: ${SEARCH_DISABLE_PUBMED:-0}

      # PubMed configuration
      PUBMED_ESEARCH_TIMEOUT_SEC: ${PUBMED_ESEARCH_TIMEOUT_SEC:-12}
      PUBMED_EFETCH_TIMEOUT_SEC: ${PUBMED_EFETCH_TIMEOUT_SEC:-20}

      # Mesh configuration
      MESH_MIN_PROBABILITY: ${MESH_MIN_PROBABILITY:-0.25}
      MESH_MAX_PARADIGMS: ${MESH_MAX_PARADIGMS:-3}

      # Evidence configuration
      EVIDENCE_SEMANTIC_SCORING: ${EVIDENCE_SEMANTIC_SCORING:-1}
      EVIDENCE_INCLUDE_SUMMARIES: ${EVIDENCE_INCLUDE_SUMMARIES:-1}

      # WebSocket configuration
      WS_KEEPALIVE_INTERVAL_SEC: ${WS_KEEPALIVE_INTERVAL_SEC:-30}

      # Feedback handling
      ENABLE_FEEDBACK_RATE_LIMIT: ${ENABLE_FEEDBACK_RATE_LIMIT:-0}
      FEEDBACK_RATE_LIMIT_PER_MINUTE: ${FEEDBACK_RATE_LIMIT_PER_MINUTE:-30}
      ENABLE_FEEDBACK_RECONCILE: ${ENABLE_FEEDBACK_RECONCILE:-0}
      FEEDBACK_RECONCILE_WINDOW_MINUTES: ${FEEDBACK_RECONCILE_WINDOW_MINUTES:-10}

    # NOTE: API keys for external services should be set via .env file or secrets
    # Required keys: AZURE_OPENAI_API_KEY, GOOGLE_API_KEY, BRAVE_API_KEY, etc.
    depends_on:
      # Wait for healthy services before starting
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    # Allow host port override via BACKEND_PORT env (defaults to 8001)
    ports:
      # Bind to localhost to avoid internet exposure; set BACKEND_PORT to override host port
      - "127.0.0.1:${BACKEND_PORT:-8001}:8000"  # host:container (loopback-only)
    restart: unless-stopped
    networks:
      - fourhosts-network
    labels:
      com.fourhosts.service: "backend"
      com.fourhosts.description: "FastAPI backend with paradigm research engine"
      com.fourhosts.endpoints: "http://localhost:8000/docs"
    healthcheck:
      # Container-internal check; uses container port 8000, not the host-mapped BACKEND_PORT
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ==========================================================================
  # FRONTEND SERVICE - React Application
  # ==========================================================================
  # User interface for paradigm-aware research queries
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: fourhosts-frontend
    depends_on:
      backend:
        condition: service_started  # Frontend can start once backend is running
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./frontend/certs:/etc/nginx/certs:ro
      - ./frontend/certbot:/var/www/certbot:ro
    restart: unless-stopped
    networks:
      - fourhosts-network
    labels:
      com.fourhosts.service: "frontend"
      com.fourhosts.description: "React frontend for Four Hosts research interface"
      com.fourhosts.url: "http://localhost"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

# ==========================================================================
# VOLUMES - Persistent Data Storage
# ==========================================================================
volumes:
  postgres_data:
  # Using minimal configuration to maintain compatibility with existing volumes
  # If you need to start fresh: docker-compose down -v

  redis_data:
# Using minimal configuration to maintain compatibility with existing volumes

# ==========================================================================
# NETWORKS - Internal Service Communication
# ==========================================================================
networks:
  fourhosts-network:
    external: true
    name: fourhosts-network

# ==========================================================================
# USAGE INSTRUCTIONS
# ==========================================================================
# 1. Start all services:        docker-compose up -d
# 2. View logs:                 docker-compose logs -f [service-name]
# 3. Stop all services:         docker-compose down
# 4. Reset data (careful!):     docker-compose down -v
# 5. Rebuild after code changes: docker-compose up -d --build
#
# ACCESS POINTS:
# - Frontend:      http://localhost
# - Backend API:   http://localhost:8001 (default, avoids Portainer on 8000)
# - API Docs:      http://localhost:8001/docs
# - PostgreSQL:    localhost:5433 (user/password/fourhosts)
# - Redis:         (internal only) redis:6379 inside Docker network
#
# MONITORING:
# - Check service health:  docker-compose ps
# - View resource usage:   docker stats
# - Inspect logs:          docker-compose logs [postgres|redis|backend|frontend]
# ==========================================================================
